fold = rep_len(1:n.folds,ndeer)
)
foldVector <- folds_df$fold[match(as.character(deer[[season]]$altid),folds_df$deer)]
predictCols <- which(names(deer[[season]])%in%pred.names)
if(type=="RF"){
fullmodel<-RFs[[season]]
}else{
fullmodel <- GLMMs[[season]]
}
CVresults <- list()
CVresults$CVpred <- numeric(nrow(deer[[season]]))
CVresults$realpred <- numeric(nrow(deer[[season]]))
CVresults$observed <- numeric(nrow(deer[[season]]))
if(type=="RF"){
response="used_fac"    #"resp_factor"
}else{
response="used"    #"resp_factor"
}
counter = 1
i=1
for(i in 1:n.folds){
if(type=="RF"){
model <- cforest(formula1, data = deer[[season]][which(foldVector!=i),], controls=cforestControl)
predict_CV  <- predict(model,newdata=deer[[season]][which(foldVector==i),],type="prob")
predict_real  <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],type="prob")
REAL <- deer[[season]]$used[which(foldVector==i)]
j=1
for(j in 1:length(which(foldVector==i))){
CVresults$CVpred[counter] <- as.numeric(predict_CV[[j]][,2])
CVresults$observed[counter] <-  as.numeric(REAL[j])
CVresults$realpred[counter] <- as.numeric(predict_real[[j]][,2])
counter = counter + 1
}
}else{
if(season=="summer"){
model <- glmer(used~stand_dist_to_water + stand_cos_aspect + stand_sin_aspect +
stand_elevation + stand_slope + veg_class + stand_elevation:stand_slope +
stand_dist_to_water:stand_slope + stand_dist_to_water:stand_elevation +
(1|altid), family="binomial", data=deer[[season]][which(foldVector!=i),],na.action="na.fail")
}else{
model <- glmer(used~stand_dist_to_water + stand_cos_aspect + stand_sin_aspect +
stand_elevation + stand_slope + veg_class +  stand_elevation:stand_slope +
stand_dist_to_water:stand_slope +
(1|altid), family="binomial", data=deer[[season]][which(foldVector!=i),],na.action="na.fail")
}
CVresults$CVpred[which(foldVector==i)]  <- plogis(predict(model,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE))
CVresults$realpred[which(foldVector==i)] <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE)
CVresults$observed[which(foldVector==i)] <- deer[[season]]$used[which(foldVector==i)]
}
}
CVresults$CV_RMSE = sqrt(mean((CVobserved-CVprediction)^2))       # root mean squared error for holdout samples in 10-fold cross-validation ...
CVresults$real_RMSE = sqrt(mean((CVobserved-realprediction)^2))   # root mean squared error for residuals from final model
# realprediction <- predict(rf_model1,newdata=df,type="prob")
graphics.off()
par(mfrow=c(2,1))
par(ask=T)
pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Cross Validation",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Full Model",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
# COHEN KAPPA statistics
thresholds <- seq(0.01,0.99,length=101)   # "artificial" extinction thresholds across which to examine performance
kappa <- numeric(length(thresholds))
for(i in 1:length(thresholds)){
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$CVpred>=thresholds[i],1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
}
#plot(thresholds,kappa,type="l",xlab="Threshold", ylab="Cohen's Kappa", main="Holdout sample performance")
# find threshold value associated with highest Kappa for C-V data
CVresults$cutoff_CV <- thresholds[which.max(kappa)]   # max kappa cutoff
kappa <- numeric(length(thresholds))
for(i in 1:length(thresholds)){
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$realpred>=thresholds[i],1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
}
#plot(thresholds,kappa,type="l",xlab="Threshold", ylab="Cohen's Kappa", main="Performance: full model")
CVresults$cutoff_full <- thresholds[which.max(kappa)]   # max kappa cutoff
### display confusion matrix and kappa for a single threshold
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$CVpred>=CVresults$cutoff_CV,1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
CVresults$bestkappa_CV <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
CVresults$confusionmat <- matrix(c(tn,fn,fp,tp),nrow=2,ncol=2)
rownames(CVresults$confusionmat) <- c("Actual not used","Actual used")
colnames(CVresults$confusionmat) <- c("Predicted not used","Predicted used")
CVresults$sensitivity <- tp/(tp+fn)
CVresults$specificity <- tn/(tn+fp)
CVresults$toterror <- (fn+fp)/tot
CVresults$CVpred[which(CVresults$CVpred==1)] <- 0.999999
CVresults$CVpred[which(CVresults$CVpred==0)] <- 0.000001
CVresults$realpred[which(CVresults$realpred==1)] <- 0.999999
CVresults$realpred[which(CVresults$realpred==0)] <- 0.000001
realdata = CVresults$observed
fit_deviance_CV <- mean(-2*(dbinom(CVresults$observed,1,CVresults$CVpred,log=T)-dbinom(realdata,1,realdata,log=T)))
fit_deviance_real <- mean(-2*(dbinom(CVresults$observed,1,CVresults$realpred,log=T)-dbinom(realdata,1,realdata,log=T)))
null_deviance <- mean(-2*(dbinom(CVresults$observed,1,mean(CVresults$observed),log=T)-dbinom(realdata,1,realdata,log=T)))
CVresults$deviance_explained_CV <- (null_deviance-fit_deviance_CV)/null_deviance   # based on holdout samples
CVresults$deviance_explained_real <- (null_deviance-fit_deviance_real)/null_deviance   # based on full model...
return(CVresults)
}
CVs <- list()
CVs[[GLMMs]] <- list()
CVs[["GLMM"]] <- list()
CVs <- list()
CVs[["GLMM"]] <- list()
CVs <- list()
CVs[["GLMM"]] <- list()
CVs[["RF"]] <- list()
uniquedeer <- as.character(unique(deer[[season]]$altid))
type= "GLMM" #"RF"
season="summer"
n.folds <- length(uniquedeer)
type= "GLMM" #"RF"
season="summer"
CVs[[type]][[season]] <- CrossValidateByDeer(n.fold=n.folds,season=season,type=type)
type= "GLMM" #"RF"
season="winter"
CVs[[type]][[season]] <- CrossValidateByDeer(n.fold=n.folds,season=season,type=type)
CrossValidateByDeer <- function(n.folds,season="summer",type="RF"){
uniquedeer <- as.character(unique(deer[[season]]$altid))
ndeer <- length(uniquedeer)
folds_df <- data.frame(
deer = uniquedeer,
fold = rep_len(1:n.folds,ndeer)
)
foldVector <- folds_df$fold[match(as.character(deer[[season]]$altid),folds_df$deer)]
predictCols <- which(names(deer[[season]])%in%pred.names)
if(type=="RF"){
fullmodel<-RFs[[season]]
}else{
fullmodel <- GLMMs[[season]]
}
CVresults <- list()
CVresults$CVpred <- numeric(nrow(deer[[season]]))
CVresults$realpred <- numeric(nrow(deer[[season]]))
CVresults$observed <- numeric(nrow(deer[[season]]))
if(type=="RF"){
response="used_fac"    #"resp_factor"
}else{
response="used"    #"resp_factor"
}
counter = 1
i=1
for(i in 1:n.folds){
if(type=="RF"){
model <- cforest(formula1, data = deer[[season]][which(foldVector!=i),], controls=cforestControl)
predict_CV  <- predict(model,newdata=deer[[season]][which(foldVector==i),],type="prob")
predict_real  <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],type="prob")
REAL <- deer[[season]]$used[which(foldVector==i)]
j=1
for(j in 1:length(which(foldVector==i))){
CVresults$CVpred[counter] <- as.numeric(predict_CV[[j]][,2])
CVresults$observed[counter] <-  as.numeric(REAL[j])
CVresults$realpred[counter] <- as.numeric(predict_real[[j]][,2])
counter = counter + 1
}
}else{
if(season=="summer"){
model <- glmer(used~stand_dist_to_water + stand_cos_aspect + stand_sin_aspect +
stand_elevation + stand_slope + veg_class + stand_elevation:stand_slope +
stand_dist_to_water:stand_slope + stand_dist_to_water:stand_elevation +
(1|altid), family="binomial", data=deer[[season]][which(foldVector!=i),],na.action="na.fail")
}else{
model <- glmer(used~stand_dist_to_water + stand_cos_aspect + stand_sin_aspect +
stand_elevation + stand_slope + veg_class +  stand_elevation:stand_slope +
stand_dist_to_water:stand_slope +
(1|altid), family="binomial", data=deer[[season]][which(foldVector!=i),],na.action="na.fail")
}
CVresults$CVpred[which(foldVector==i)]  <- plogis(predict(model,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE))
CVresults$realpred[which(foldVector==i)] <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE)
CVresults$observed[which(foldVector==i)] <- deer[[season]]$used[which(foldVector==i)]
}
}
CVresults$CV_RMSE = sqrt(mean((CVresults$observed-CVresults$CVpred)^2))       # root mean squared error for holdout samples in 10-fold cross-validation ...
CVresults$real_RMSE = sqrt(mean((CVresults$observed-CVresults$realpred)^2))   # root mean squared error for residuals from final model
# realprediction <- predict(rf_model1,newdata=df,type="prob")
graphics.off()
par(mfrow=c(2,1))
par(ask=T)
pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Cross Validation",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Full Model",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
# COHEN KAPPA statistics
thresholds <- seq(0.01,0.99,length=101)   # "artificial" extinction thresholds across which to examine performance
kappa <- numeric(length(thresholds))
for(i in 1:length(thresholds)){
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$CVpred>=thresholds[i],1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
}
#plot(thresholds,kappa,type="l",xlab="Threshold", ylab="Cohen's Kappa", main="Holdout sample performance")
# find threshold value associated with highest Kappa for C-V data
CVresults$cutoff_CV <- thresholds[which.max(kappa)]   # max kappa cutoff
kappa <- numeric(length(thresholds))
for(i in 1:length(thresholds)){
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$realpred>=thresholds[i],1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
}
#plot(thresholds,kappa,type="l",xlab="Threshold", ylab="Cohen's Kappa", main="Performance: full model")
CVresults$cutoff_full <- thresholds[which.max(kappa)]   # max kappa cutoff
### display confusion matrix and kappa for a single threshold
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$CVpred>=CVresults$cutoff_CV,1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
CVresults$bestkappa_CV <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
CVresults$confusionmat <- matrix(c(tn,fn,fp,tp),nrow=2,ncol=2)
rownames(CVresults$confusionmat) <- c("Actual not used","Actual used")
colnames(CVresults$confusionmat) <- c("Predicted not used","Predicted used")
CVresults$sensitivity <- tp/(tp+fn)
CVresults$specificity <- tn/(tn+fp)
CVresults$toterror <- (fn+fp)/tot
CVresults$CVpred[which(CVresults$CVpred==1)] <- 0.999999
CVresults$CVpred[which(CVresults$CVpred==0)] <- 0.000001
CVresults$realpred[which(CVresults$realpred==1)] <- 0.999999
CVresults$realpred[which(CVresults$realpred==0)] <- 0.000001
realdata = CVresults$observed
fit_deviance_CV <- mean(-2*(dbinom(CVresults$observed,1,CVresults$CVpred,log=T)-dbinom(realdata,1,realdata,log=T)))
fit_deviance_real <- mean(-2*(dbinom(CVresults$observed,1,CVresults$realpred,log=T)-dbinom(realdata,1,realdata,log=T)))
null_deviance <- mean(-2*(dbinom(CVresults$observed,1,mean(CVresults$observed),log=T)-dbinom(realdata,1,realdata,log=T)))
CVresults$deviance_explained_CV <- (null_deviance-fit_deviance_CV)/null_deviance   # based on holdout samples
CVresults$deviance_explained_real <- (null_deviance-fit_deviance_real)/null_deviance   # based on full model...
return(CVresults)
}
type= "GLMM" #"RF"
season="summer"
CVs[[type]][[season]] <- CrossValidateByDeer(n.fold=n.folds,season=season,type=type)
type= "GLMM" #"RF"
season="winter"
CVs[[type]][[season]] <- CrossValidateByDeer(n.fold=n.folds,season=season,type=type)
CVs$GLMM$summer
CrossValidateByDeer <- function(n.folds,season="summer",type="RF",plot=F){
uniquedeer <- as.character(unique(deer[[season]]$altid))
ndeer <- length(uniquedeer)
folds_df <- data.frame(
deer = uniquedeer,
fold = rep_len(1:n.folds,ndeer)
)
foldVector <- folds_df$fold[match(as.character(deer[[season]]$altid),folds_df$deer)]
predictCols <- which(names(deer[[season]])%in%pred.names)
if(type=="RF"){
fullmodel<-RFs[[season]]
}else{
fullmodel <- GLMMs[[season]]
}
CVresults <- list()
CVresults$CVpred <- numeric(nrow(deer[[season]]))
CVresults$realpred <- numeric(nrow(deer[[season]]))
CVresults$observed <- numeric(nrow(deer[[season]]))
if(type=="RF"){
response="used_fac"    #"resp_factor"
}else{
response="used"    #"resp_factor"
}
counter = 1
i=1
for(i in 1:n.folds){
if(type=="RF"){
model <- cforest(formula1, data = deer[[season]][which(foldVector!=i),], controls=cforestControl)
predict_CV  <- predict(model,newdata=deer[[season]][which(foldVector==i),],type="prob")
predict_real  <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],type="prob")
REAL <- deer[[season]]$used[which(foldVector==i)]
j=1
for(j in 1:length(which(foldVector==i))){
CVresults$CVpred[counter] <- as.numeric(predict_CV[[j]][,2])
CVresults$observed[counter] <-  as.numeric(REAL[j])
CVresults$realpred[counter] <- as.numeric(predict_real[[j]][,2])
counter = counter + 1
}
}else{
if(season=="summer"){
model <- glmer(used~stand_dist_to_water + stand_cos_aspect + stand_sin_aspect +
stand_elevation + stand_slope + veg_class + stand_elevation:stand_slope +
stand_dist_to_water:stand_slope + stand_dist_to_water:stand_elevation +
(1|altid), family="binomial", data=deer[[season]][which(foldVector!=i),],na.action="na.fail")
}else{
model <- glmer(used~stand_dist_to_water + stand_cos_aspect + stand_sin_aspect +
stand_elevation + stand_slope + veg_class +  stand_elevation:stand_slope +
stand_dist_to_water:stand_slope +
(1|altid), family="binomial", data=deer[[season]][which(foldVector!=i),],na.action="na.fail")
}
CVresults$CVpred[which(foldVector==i)]  <- plogis(predict(model,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE))
CVresults$realpred[which(foldVector==i)] <-  predict(fullmodel,newdata=deer[[season]][which(foldVector==i),],allow.new.levels = TRUE)
CVresults$observed[which(foldVector==i)] <- deer[[season]]$used[which(foldVector==i)]
}
}
CVresults$CV_RMSE = sqrt(mean((CVresults$observed-CVresults$CVpred)^2))       # root mean squared error for holdout samples in 10-fold cross-validation ...
CVresults$real_RMSE = sqrt(mean((CVresults$observed-CVresults$realpred)^2))   # root mean squared error for residuals from final model
# realprediction <- predict(rf_model1,newdata=df,type="prob")
if(plot){
graphics.off()
par(mfrow=c(2,1))
par(ask=T)
pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Cross Validation",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Full Model",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
}else{
pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
CVresults$auc_CV <- performance(pred,"auc")
pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model
perf <- performance(pred,"tpr","fpr")
CVresults$auc_full <- performance(pred,"auc")
}
# COHEN KAPPA statistics
thresholds <- seq(0.01,0.99,length=101)   # "artificial" extinction thresholds across which to examine performance
kappa <- numeric(length(thresholds))
for(i in 1:length(thresholds)){
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$CVpred>=thresholds[i],1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
}
#plot(thresholds,kappa,type="l",xlab="Threshold", ylab="Cohen's Kappa", main="Holdout sample performance")
# find threshold value associated with highest Kappa for C-V data
CVresults$cutoff_CV <- thresholds[which.max(kappa)]   # max kappa cutoff
kappa <- numeric(length(thresholds))
for(i in 1:length(thresholds)){
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$realpred>=thresholds[i],1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
}
#plot(thresholds,kappa,type="l",xlab="Threshold", ylab="Cohen's Kappa", main="Performance: full model")
CVresults$cutoff_full <- thresholds[which.max(kappa)]   # max kappa cutoff
### display confusion matrix and kappa for a single threshold
trueLabels <- CVresults$observed
predLabels <- ifelse(CVresults$CVpred>=CVresults$cutoff_CV,1,0)
tot <- length(CVresults$observed)
tp <- length(which((trueLabels==1)&(predLabels==1)))
tn <- length(which((trueLabels==0)&(predLabels==0)))
fp <- length(which((trueLabels==0)&(predLabels==1)))
fn <- length(which((trueLabels==1)&(predLabels==0)))
pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy
pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)
CVresults$bestkappa_CV <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)
CVresults$confusionmat <- matrix(c(tn,fn,fp,tp),nrow=2,ncol=2)
rownames(CVresults$confusionmat) <- c("Actual not used","Actual used")
colnames(CVresults$confusionmat) <- c("Predicted not used","Predicted used")
CVresults$sensitivity <- tp/(tp+fn)
CVresults$specificity <- tn/(tn+fp)
CVresults$toterror <- (fn+fp)/tot
CVresults$CVpred[which(CVresults$CVpred==1)] <- 0.999999
CVresults$CVpred[which(CVresults$CVpred==0)] <- 0.000001
CVresults$realpred[which(CVresults$realpred==1)] <- 0.999999
CVresults$realpred[which(CVresults$realpred==0)] <- 0.000001
realdata = CVresults$observed
fit_deviance_CV <- mean(-2*(dbinom(CVresults$observed,1,CVresults$CVpred,log=T)-dbinom(realdata,1,realdata,log=T)))
fit_deviance_real <- mean(-2*(dbinom(CVresults$observed,1,CVresults$realpred,log=T)-dbinom(realdata,1,realdata,log=T)))
null_deviance <- mean(-2*(dbinom(CVresults$observed,1,mean(CVresults$observed),log=T)-dbinom(realdata,1,realdata,log=T)))
CVresults$deviance_explained_CV <- (null_deviance-fit_deviance_CV)/null_deviance   # based on holdout samples
CVresults$deviance_explained_real <- (null_deviance-fit_deviance_real)/null_deviance   # based on full model...
return(CVresults)
}
CVs[[type]][[season]]
CVs[[type]][[season]]
type= "GLMM" #"RF"
season="summer"
CVs[[type]][[season]]
type= "GLMM" #"RF"
season="winter"
CVs[[type]][[season]]
type= "RF" #"RF"
season="summer"
CVs[[type]][[season]] <- CrossValidateByDeer(n.fold=n.folds,season=season,type=type,plot=F)
type= "RF" #"RF"
season="winter"
CVs[[type]][[season]] <- CrossValidateByDeer(n.fold=n.folds,season=season,type=type,plot=F)
setwd("E:\\Dropbox\\Mule Deer\\Methods paper\\CODE_deprecated")
setwd("E:\\Dropbox\\Mule Deer\\Methods paper\\CODE_deprecated")
save(CVs,file = "CVs.RData")
PlotPerformance <- function(CVresults){
graphics.off()
par(mfrow=c(2,1))
par(ask=T)
pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Cross Validation",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Full Model",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
}
type= "GLMM" #"RF"
season="summer"
PlotPerformance(CVs[[type]][[season]])
PlotPerformance <- function(CVresults){
graphics.off()
par(mfrow=c(2,1))
#par(ask=T)
pred <- prediction(CVresults$CVpred,CVresults$observed)     # for holdout samples in cross-validation
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Cross Validation",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
pred <- prediction(CVresults$realpred,CVresults$observed)     # for final model
perf <- performance(pred,"tpr","fpr")
auc <- performance(pred,"auc")
plot(perf, main=sprintf("%s Full Model",type))
text(.9,.1,paste("AUC = ",round(auc@y.values[[1]],2),sep=""))
}
type= "GLMM" #"RF"
season="winter"
PlotPerformance(CVs[[type]][[season]])
type= "RF" #"RF"
season="summer"
PlotPerformance(CVs[[type]][[season]])
type= "RF" #"RF"
season="winter"
PlotPerformance(CVs[[type]][[season]])
type= "GLMM" #"RF"
season="winter"
PlotPerformance(CVs[[type]][[season]])
type= "RF" #"RF"
season="summer"
PlotPerformance(CVs[[type]][[season]])
type= "GLMM" #"RF"
season="winter"
PlotPerformance(CVs[[type]][[season]])
type= "GLMM" #"RF"
season="summer"
PlotPerformance(CVs[[type]][[season]])
type= "RF" #"RF"
season="summer"
PlotPerformance(CVs[[type]][[season]])
?roc.test
roc1 <- roc(CVs$GLMM[[season]]$observed,CVs$GLMM[[season]])
CVs$GLMM[[season]]$observed
roc1 <- roc(CVs$GLMM[[season]]$observed,CVs$GLMM[[season]]$CVpred)
roc2 <- roc(CVs$RF[[season]]$observed,CVs$RF[[season]]$CVpred)
roc.test(roc1, roc2)
season="winter"
roc1 <- roc(CVs$GLMM[[season]]$observed,CVs$GLMM[[season]]$CVpred)
roc2 <- roc(CVs$RF[[season]]$observed,CVs$RF[[season]]$CVpred)
roc.test(roc1, roc2)
