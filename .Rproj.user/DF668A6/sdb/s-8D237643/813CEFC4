{
    "collab_server" : "",
    "contents" : "## read in data\n\ndf <- read.csv(\"summer_main_modeldata_new10April2017.csv\")\n\nhead(df)\n\n\n#Define catagorical variables as factors\n#oc$HabMode<-as.factor(oc$HabMode)\n\ndf$used=factor(df$used)\ndf$veg_class=factor(df$veg_class)\n\n#IMPORTANT: When using categorical variables, make sure they are encoded as factors, not as numeric.\n#Use class(data$Resp) to check the encoding, and use as.factor(data$Resp) to encode your vector as a \n#factor.) \n\n\n############### NAMING VARIABLES ############\n\npredictorNames <- c(  \"Cos Aspect\", # nice readable names\n                      \"Sin Aspect\",\n                      \"Elevation\",\n                      \"Slope\",\n                      \"Vegetation Class\",\n                      \"Distance to Water\"\n)\n\npred.names=c(  \"cos_aspect\",\n               \"sin_aspect\",\n               \"elevation\",\n               \"slope\",\n               \"veg_class\",\n               \"dist_to_water\"\n               \n)\n\n\n#name check\ncbind(pred.names,predictorNames)\n\n\n#### Define response variable\n\nresponse=\"used\"   \n\n\n\n#### Define our formula (response ~ predictors)\n\nformula1 <- as.formula(paste(response,\"~\",paste(pred.names,collapse=\"+\")))\n\n\n#### Read in the script from github\n\nsource(\"RF_Extensions.R\")   # change to your script locations\n\n##### CONDITIONAL INFERENCE TREE  ##################\n\nsummer_deer <- ctree(formula=formula1, data=df, controls = ctree_control(mincriterion = 0.99,maxdepth = 4))\n\nplot(summer_deer)\n\nsummary(summer_deer)\n\n###########################################################\n###############  CFOREST #################\n\ncforestControl <- cforest_unbiased(ntree=500,mtry=2)   # change back to 500!!\ncforestControl@fraction <- 0.03\n\nrf_model1 <- cforest(formula1, controls=cforestControl, data=df)\n\n    # get the importance values\nmodel1_importance<-varimp((rf_model1), conditional= FALSE)\n\ngraphics.off()\nlengthndx <- length(model1_importance)\n#par(mai=c(0.95,3.1,0.6,0.4))\npar(mai=c(1.4,3.4,0.6,0.9))\ncol <- rainbow(lengthndx, start = 3/6, end = 4/6)      # rep(brewer.pal(6,\"Blues\"),each=2)\nbarplot(height=model1_importance[order(model1_importance,decreasing = FALSE)],\n        horiz=T,las=1,main=\"Order of Importance of Predictor Variables\",\n        xlab=\"Index of overall importance\",col=col,           \n        names.arg=predictorNames[match(names(model1_importance),pred.names)][order(model1_importance,decreasing = FALSE)])\n\n\n\n#PREDICTIONS\n\n#predictions as probabilities\ntemp <- predict(rf_model1,type=\"prob\")\npredictions1<-numeric(nrow(newX_listed))\nfor(i in 1:nrow(newX_listed)){\n  predictions1[i]<-temp[[i]][2]}\n#PRINT probabilities PREDICTIONS FILE\n#Mainpredict1 <- data.frame(newX_listed,predictions1)\n#write.table(Mainpredict1, file = \"TerrMamm_Predictions_Raw_prob.txt\")\n\n# get predicitons as 1's and 0's\n#predictions <- predict(rf_model1,type=\"response\")\n#PRINT 0's and 1's PREDICTIONS FILE\npredictions <- ifelse(predictions1>=cutoff,1,0)\nMainpredict <- data.frame(newX_listed,predictions,predictions1)\n\nwrite.table(Mainpredict, file = \"Winter_Predictions_Raw.txt\")\n\n\n##### Make univariate plots of the relationships- plot all relationships at once\n\nRF_UnivariatePlots(object=rf_model1, varimp=model1_importance, data=df,  #   \n                   predictors=pred.names, labels=predictorNames, allpredictors=pred.names,plot.layout=c(2,2))\n\n\n\n##### Make univariate plots of the relationships- plot one relationship at a time\n\nRF_UnivariatePlots(object=rf_model1, varimp=model1_importance, data=df,  #   \n                   predictors=pred.names[6], labels=predictorNames[6], allpredictors=pred.names,plot.layout=c(1,1))\n\n\n# return the data for plotting\nPlotData <- RF_UnivariatePlots(object=rf_model1, varimp=model1_importance, data=df,  #   \n                   predictors=pred.names, labels=predictorNames, allpredictors=pred.names, plot.layout=c(1,1),plot=F)\n\n\n\n####################################\n#######################   RANDOM FOREST FIND AND PLOT INTERACTIONS\n\n# NOTE: this one can take a very long time   ...\nrf_findint <- RF_FindInteractions(object=rf_model1,data=df,predictors=pred.names)\n\n# display and plot out interactions...\nrf_findint$interactions1\n\nrf_findint$rank.list1\n\n### plot interaction strength\ngraphics.off()\nlengthndx <- min(9,nrow(rf_findint$rank.list1))\npar(mai=c(0.95,3.1,0.6,0.4))\n#ndx <- ndx <- which(predictors%in%pred.names)\nbarplot(height=(rf_findint$rank.list1[c(1:min(9,nrow(rf_findint$rank.list1))),5][c(lengthndx:1)]),\n        horiz=T,las=1,main=paste(response, sep=\"\"),\n        xlab=\"Index of interaction strength\",col=brewer.pal(lengthndx,\"Blues\"),           \n        names.arg=paste(\"\",predictorNames[match(rf_findint$rank.list1[,2][c(lengthndx:1)],pred.names)],\"\\n\",predictorNames[match(rf_findint$rank.list1[,4][c(lengthndx:1)],pred.names)],sep=\"\") )\n\ngraphics.off()\n\n\nrf_findint$rank.list1\n\n\n\nfam=\"binomial\"\ngraphics.off()\n#svg(filename = \"IntFig2.svg\",\n    # width = 7, height = 7, pointsize = 12,\n    # onefile = TRUE, family = \"sans\", bg = \"white\")\n\n#### visualize the interactions\n\nRF_InteractionPlots(x=6,y=3,object=rf_model1,data=df,predictors=pred.names,family=fam)\ninter2 <- recordPlot()\nRF_InteractionPlots(x=4,y=3,object=rf_model1,data=df,predictors=pred.names,family=fam) \ninter1 <- recordPlot()\n\ndev.off()\ngraphics.off()\n\n\n\n\n\n###################################\n#################### CROSS VALIDATION CODE\n\n\nn.folds <- 9\ndf$altid\nuniquedeer <- as.character(unique(df$altid))\nfolds_df <- data.frame(\n  deer = uniquedeer,\n  fold = c(rep(1:n.folds,each=5),1,2)\n)\n\nfoldVector <- folds_df$fold[match(as.character(df$altid),folds_df$deer)]\n\ncounter = 1\nCVprediction <- numeric(nrow(df))\nCVobserved <- numeric(nrow(df))\nrealprediction <- numeric(nrow(df))\nrealdata <- numeric(nrow(df))\n\npredictCols <- which(names(df)%in%pred.names)\n\ndata.controls = cforest_unbiased(ntree=50)\ncounter=1\nresponse=\"used\"    #\"resp_factor\"\n\n#test <- numeric(nrow(df))\n\ni=1\nfor(i in 1:n.folds){\n  model <- cforest(formula1, data = df[which(foldVector!=i),], controls=cforestControl) \n  predict_CV  <- predict(model,newdata=df[which(foldVector==i),],type=\"prob\") \n  predict_real  <-  predict(rf_model1,newdata=df[which(foldVector==i),],type=\"prob\")\n  REAL <- df$used[which(foldVector==i)]\n  j=1\n  for(j in 1:length(which(foldVector==i))){\n    CVprediction[counter] <- as.numeric(predict_CV[[j]][,2])\n    CVobserved[counter] <-  as.numeric(REAL[j])      \n    realprediction[counter] <- as.numeric(predict_real[[j]][,2])   \n    realdata[counter] <- as.numeric(REAL[j])         \n    counter = counter + 1  \n  }\n}\n\nfact=TRUE\nif(fact){\n  CVobserved = CVobserved-1\n  realdata=realdata-1\n}\n\nCV_RMSE = sqrt(mean((CVobserved-CVprediction)^2))       # root mean squared error for holdout samples in 10-fold cross-validation ...\nreal_RMSE = sqrt(mean((CVobserved-realprediction)^2))  # root mean squared error for residuals from final model\n\n# print RMSE statistics\nCV_RMSE \nwrite.csv(CV_RMSE,file=\"CV_RMSE_10percent.csv\")\nreal_RMSE\nwrite.csv(real_RMSE,file=\"real_RMSE_10percent.csv\")\n\n\n# realprediction <- predict(rf_model1,newdata=df,type=\"prob\")\n\nbinaryresponse=TRUE\n\nif(binaryresponse){\n  graphics.off()\n  par(mfrow=c(2,1))\n  pred <- prediction(CVprediction,CVobserved)     # for holdout samples in cross-validation\n  perf <- performance(pred,\"tpr\",\"fpr\")\n  auc <- performance(pred,\"auc\")\n  plot(perf, main=\"RF Cross Validation\")\n  text(.9,.1,paste(\"AUC = \",round(auc@y.values[[1]],2),sep=\"\"))\n  \n  pred <- prediction(realprediction,CVobserved)     # for final model\n  perf <- performance(pred,\"tpr\",\"fpr\")\n  auc <- performance(pred,\"auc\")\n  plot(perf, main=\"Random Forest Model\")\n  text(.9,.1,paste(\"AUC = \",round(auc@y.values[[1]],2),sep=\"\"))\n}\n\n\n# COHEN KAPPA statistics\n\ngraphics.off()\npar(mfrow=c(2,1))\nthresholds <- seq(0.01,0.99,length=101)   # \"artificial\" extinction thresholds across which to examine performance\nkappa <- numeric(length(thresholds))\nfor(i in 1:length(thresholds)){\n  trueLabels <- CVobserved\n  predLabels <- ifelse(CVprediction>=thresholds[i],1,0)\n  tot <- length(CVobserved)\n  tp <- length(which((trueLabels==1)&(predLabels==1)))  \n  tn <- length(which((trueLabels==0)&(predLabels==0)))\n  fp <- length(which((trueLabels==0)&(predLabels==1)))\n  fn <- length(which((trueLabels==1)&(predLabels==0)))\n  pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy\n  pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)\n  kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)\n}\nplot(thresholds,kappa,type=\"l\",xlab=\"Threshold\", ylab=\"Cohen's Kappa\", main=\"Holdout sample performance\")\n\n# find threshold value associated with highest Kappa for C-V data\n\ncutoff <- thresholds[which.max(kappa)]\ncutoff\n\n\nkappa <- numeric(length(thresholds)) \nfor(i in 1:length(thresholds)){\n  trueLabels <- CVobserved\n  predLabels <- ifelse(realprediction>=thresholds[i],1,0)    \n  tot <- length(CVobserved)\n  tp <- length(which((trueLabels==1)&(predLabels==1)))  \n  tn <- length(which((trueLabels==0)&(predLabels==0)))\n  fp <- length(which((trueLabels==0)&(predLabels==1)))\n  fn <- length(which((trueLabels==1)&(predLabels==0)))\n  pr_agree <- (tp+tn)/tot    # overall agreement, or accuracy\n  pr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)\n  kappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)\n}\nplot(thresholds,kappa,type=\"l\",xlab=\"Threshold\", ylab=\"Cohen's Kappa\", main=\"Performance: full model\")\n\n\n\n### display confusion matrix and kappa for a single threshold\ntrueLabels <- CVobserved\npredLabels <- ifelse(CVprediction>=cutoff,1,0)    \ntot <- length(CVobserved)\ntp <- length(which((trueLabels==1)&(predLabels==1)))  \ntn <- length(which((trueLabels==0)&(predLabels==0)))\nfp <- length(which((trueLabels==0)&(predLabels==1)))\nfn <- length(which((trueLabels==1)&(predLabels==0)))\npr_agree <- (tp+tn)/tot    # overall agreement, or accuracy\npr_agree_rand <- ((tp+fn)/tot)*((tp+fp)/tot)+((fn+tn)/tot)*((fp+tn)/tot)\nkappa[i] <- (pr_agree-pr_agree_rand)/(1-pr_agree_rand)\nkappa[i]\nmatrix(c(tp,fp,fn,tn),nrow=2,ncol=2)\nsensitivity <- tp/(tp+fn)\nspecificity <- tn/(tn+fp)\ntoterror <- (fn+fp)/tot\nsensitivity\nspecificity\ntoterror\n\nif(binaryresponse){\n  CVprediction[which(CVprediction==1)] <- 0.9999\n  CVprediction[which(CVprediction==0)] <- 0.0001\n  realprediction[which(realprediction==1)] <- 0.9999\n  realprediction[which(realprediction==0)] <- 0.0001\n}\n\n\nrealdata = CVobserved\nfit_deviance_CV <- mean((CVobserved-CVprediction)^2)\nif(binaryresponse) fit_deviance_CV <- mean(-2*(dbinom(CVobserved,1,CVprediction,log=T)-dbinom(realdata,1,realdata,log=T)))\nfit_deviance_real <- mean((CVobserved-realprediction)^2)\nif(binaryresponse) fit_deviance_real <- mean(-2*(dbinom(CVobserved,1,realprediction,log=T)-dbinom(realdata,1,realdata,log=T)))\nnull_deviance <- mean((CVobserved-mean(CVobserved))^2)\nif(binaryresponse) null_deviance <- mean(-2*(dbinom(CVobserved,1,mean(CVobserved),log=T)-dbinom(realdata,1,realdata,log=T)))\ndeviance_explained_CV <- (null_deviance-fit_deviance_CV)/null_deviance   # based on holdout samples\ndeviance_explained_real <- (null_deviance-fit_deviance_real)/null_deviance   # based on full model...\n\ndeviance_explained_CV\ndeviance_explained_real\n\n\n",
    "created" : 1507170717987.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "384813809",
    "id" : "813CEFC4",
    "lastKnownWriteTime" : 1493231064,
    "last_content_update" : 1493231064,
    "path" : "E:/Dropbox/Mule Deer/Methods paper/CODE_deprecated/Winter_Random_ Forest_Script.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}